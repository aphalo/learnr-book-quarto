[
  {
    "objectID": "wordcloud.html",
    "href": "wordcloud.html",
    "title": "The Word Cloud on the Book Cover",
    "section": "",
    "text": "I created the word clouds on the covers of both editions of “Learn R: As a Language” using an R script that takes as input the file with the R objects and functions included in the R index of the books. The index file was generated when creating the PDF from the LaTeX source files as an word list as simple of possible, not printed as part of the book but including the same terms. This input file still contained some additional information, like page numbers that needed to be stripped into a clean list of words. I here present the R used code for the 2nd edition. If you want to do something similar for your own book, report or thesis you can easily reuse this code after some edits."
  },
  {
    "objectID": "wordcloud.html#introduction",
    "href": "wordcloud.html#introduction",
    "title": "The Word Cloud on the Book Cover",
    "section": "",
    "text": "I created the word clouds on the covers of both editions of “Learn R: As a Language” using an R script that takes as input the file with the R objects and functions included in the R index of the books. The index file was generated when creating the PDF from the LaTeX source files as an word list as simple of possible, not printed as part of the book but including the same terms. This input file still contained some additional information, like page numbers that needed to be stripped into a clean list of words. I here present the R used code for the 2nd edition. If you want to do something similar for your own book, report or thesis you can easily reuse this code after some edits."
  },
  {
    "objectID": "wordcloud.html#the-word-cloud",
    "href": "wordcloud.html#the-word-cloud",
    "title": "The Word Cloud on the Book Cover",
    "section": "2 The word cloud",
    "text": "2 The word cloud\nThe word cloud that appears on the cover of the book is based on the frequency, or number of times, with which each R function or command appears in the index included at the back of the book. The wordcloud is a ggplot where frequency is mapped to both colour and size aesthetics and the text of the index entries is mapped to the label aesthetic. The positioning is automatically done by geom_text_wordcloud(). I used one of the Viridis colour scales.\n\n\n\nWordcloud on book cover"
  },
  {
    "objectID": "wordcloud.html#reusable-code",
    "href": "wordcloud.html#reusable-code",
    "title": "The Word Cloud on the Book Cover",
    "section": "3 Reusable code",
    "text": "3 Reusable code\nFirst I need to explain how I encoded index entries in the \\(\\LaTeX\\) .Rnw source files. I did not use \\index directly in the .Rnw source file but instead defined macros wrapping this command from index building system of \\(\\LaTeX\\). In the case of macros for indexing R related words, the macros also added the mark up (font and shading) used in the main text in the same operation. In fact, I defined different macros for functions, classes, etc., even if some of the definitions were initially identical. This added a lot of flexibility; a flexibility that helped greatly when implementing the code for the word cloud.\nI show here only the macro for R functions as an example, although I also used similar macros for methods, classes, operators, etc., which allowed automating the hierarchical grouping of entries in the R indices printed in the book.\n\n\\newcommand{\\Rfunction}[1]{\\code{#1}\\index[rindex]{#1@\\texttt{#1}}\\index[rcatsidx]{functions and methods!#1@\\texttt{#1}}\\index[cloudindex]{#1}\\xspace}\n\nThose familiar with \\(\\LaTeX\\) will notice that the macro as defined above adds the argument to three different indexes, and encodes the argument in a “typewriter” font both in the main text and the first two indexes. The third “index” is a list of words without formatting mark-up saved in a file named cloudindex.idx. The generate this file I added \\index[cloudindex]{#1} to this and similar \\\\(\\LaTeX\\) macros. I also added in the preamble of the book’s main source .Rnw file \\makeindex[name=cloudindex] but did not add a \\printindex for this index, so that it is not included in the book PDF.\nThe file cloudindex.idx contains rows ordered by page number, containing one row for each call to \\index in the manuscript (only the first few out of 1666 lines are shown):\n\n\\indexentry{help()}{16}\n\\indexentry{help()}{17}\n\\indexentry{help()}{17}\n\\indexentry{print()}{18}\n\\indexentry{numeric}{24}\n\\indexentry{+}{24}\n\\indexentry{-}{24}\n\\indexentry{*}{24}\n\\indexentry{/}{24}\n\\indexentry{exp()}{25}\n\\indexentry{cos()}{25}\n\\indexentry{pi}{25}\n\\indexentry{pi}{25}\n\\indexentry{cos()}{25}\n\\indexentry{sqrt()}{25}\n\\indexentry{sin()}{25}\n\\indexentry{log()}{25}\n\\indexentry{log10()}{25}\n...\n\nThe R code used for extracting words, counting the number of entries for each word and assembling a tibble suitable as data argument for ggplot() is shown next. This script could be simplified still.\n\nlibrary(ngram)\nlibrary(ggplot2)\nlibrary(ggwordcloud)\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(stringr)\nlibrary(wrapr)\n\n# define a function to extract index entries\n# some of this is redundant for simple word lists\nclean_words &lt;- function(x) { x %.&gt;%\n    # remove laTeX commands\n    gsub(\"\\\\\\\\indexentry|\\\\\\\\textbar|\\\\\\\\ldots\", \"\", x = .) %.&gt;%\n    # remove page numbers\n    gsub(\"[{][0-9]*[}]\", \"\", x = .) %.&gt;%\n    # remove all quotation marks\n    gsub('\\\\\\\\\\\"|\\\\\\\"|\\\\\"', '', x = .) %.&gt;%\n    # replace scaped characters\n    gsub(\"\\\\\\\\_\", \"_\", x = .) %.&gt;%\n    gsub(\"\\\\\\\\%\", \"%\", x = .) %.&gt;%\n    gsub(\"\\\\\\\\[$]|\\\\[$]\", \"$\", x = .) %.&gt;% # $ needs to be protected\n    gsub(\"\\\\\\\\&|\\\\&\", \"&\", x = .) %.&gt;%\n    gsub(\"\\\\\\\\^|\\\\^\", \"^\", x = .) %.&gt;%\n    # remove brackets\n    gsub(\"[{]|[}]\", \"\", x = .) %.&gt;%\n    gsub(\"@\\\\texttt\", \"\", x = ., fixed = TRUE)\n}\n\n# copy most recent .idx files for book\n# file.copy(from = \"../learnr-book-crc/cloudindex.idx\", \".\")\n\n# read all index files, each one into a single character string\nlist.files(path = \".\", pattern = \"*.idx$\")\nindexed.words &lt;- multiread(extension=\".idx\", prune.empty = FALSE)\n# find the index we want to use\nnames(indexed.words)\n\n# we grab the first one (edit index \"1\" as needed)\nmy.idx &lt;- clean_words(indexed.words[[1]]) \nmy.idx &lt;- gsub(\"[ ]\", \"[]\", my.idx, fixed = TRUE)\nmy.idx &lt;- gsub(\"[ , ]\", \"[,]\", my.idx, fixed = TRUE)\nmy.idx &lt;- gsub(\"if ()\", \"if\", my.idx, fixed = TRUE)\nmy.idx &lt;- gsub(\"\\\\textbackslash\", \"\\\\\", my.idx, fixed = TRUE)\nmy.idx &lt;- gsub(\"\\\\textbackslash(.?)\", \"\\\\()\", my.idx, fixed = TRUE)\nmy.idx &lt;- gsub(\"\\\\^\", \"^\", my.idx, fixed = TRUE)\n\n# check what we have got \nstring.summary(my.idx) \n# split index entries into strings, sort and count their frequency \nmy.idx %.&gt;%\n  str_split(., \" \") %.&gt;%\n  unlist(.) %.&gt;%\n  sort(.) %.&gt;%\n  rle(.) %.&gt;% # rle is \"run length encoding\"\n  tibble(lengths = .$lengths, values = .$values) %.&gt;%\n  filter(., !values %in% c(\"\", \"NA\")) %.&gt;% # to be excluded\n  dplyr::arrange(., desc(lengths)) -&gt; word_counts.tb\n\nword_counts.tb$values &lt;- gsub(\"[]\", \"[ ]\", word_counts.tb$values, fixed = TRUE)\nword_counts.tb$values &lt;- gsub(\"[,]\", \"[ , ]\", word_counts.tb$values, fixed = TRUE)\nword_counts.tb$values &lt;- ifelse(word_counts.tb$values == \"()\", \"\\\\()\", word_counts.tb$values)\nword_counts.tb &lt;- word_counts.tb[order(word_counts.tb$values), ][-(1:43), ]\nword_counts.tb &lt;- word_counts.tb[order(-word_counts.tb$lengths), ]\n\n# number of distinct index entries\nnrow(word_counts.tb)\n# the six most frequent index entries\nhead(word_counts.tb)\n\nWe plot the data as a word cloud using ‘ggplot2’ and package ‘ggwordcloud’. The values used as arguments for grid_margin, max_size, and the number of index entries or “words” plotted were selected by trial and error.\n\nword_cloud.fig0 &lt;-\n # we use the 180 most frequent entries\n  ggplot(word_counts.tb[1:180, ],\n         aes(label = values,\n             size = lengths,\n             color = lengths)) +\n  geom_text_wordcloud(family = \"mono\",\n                      fontface = \"bold\",\n                      area_corr = TRUE,\n                      grid_margin = 2,\n                      seed = 42,\n                      use_richtext = FALSE) +\n  scale_size_area(max_size = 12) +\n  scale_color_viridis_c() +\n  theme_minimal() +\n  theme(aspect.ratio = 5/6)\n\nWe next give examples of how to create PNG files and of how style variations can also produced by “editing” a ggplot to replace the colour scale. It is important to be aware, that in these examples the background colour was set when calling the png() device (equivalent to feeding paper of a different colour to a printer) as is not coded as part of the ggplot. Of course, other R graphic devices can be used as well.\n\n# note that the background color is set when opening the device\npng(\"images/learnrbook-cover-image-300-0.png\",\n    width = 2100, height = 1500, res = 300, bg = \"black\")\nprint(word_cloud.fig0)\ndev.off()\n\n\n\n\nWord cloud\n\n\n\n# two examples using different palettes\nword_cloud.fig1 &lt;-\n  word_cloud.fig0 %+% scale_color_viridis_c(option = \"B\", begin = 0.4)\n\npng(\"images/learnrbook-cover-image-300-1.png\",\n    width = 2100, height = 1500, res = 300, bg = \"#150030\")\nprint(word_cloud.fig1)\ndev.off()\n\n\n\n\nWord cloud\n\n\n\nword_cloud.fig2 &lt;-\n  word_cloud.fig0 %+% scale_color_viridis_c(option = \"C\")\n\npng(\"images/learnrbook-cover-image-300-2.png\",\n    width = 2100, height = 1500, res = 300, bg = \"black\")\nprint(word_cloud.fig2)\ndev.off()\n\n\n\n\nWord cloud\n\n\nIn fact once we realize what needs to be done, and which are the most appropriate tools, a simple script can get the job done elegantly."
  },
  {
    "objectID": "preface-1ed.html",
    "href": "preface-1ed.html",
    "title": "First edition (2020)",
    "section": "",
    "text": "The book cover (1ed)"
  },
  {
    "objectID": "preface-1ed.html#preface",
    "href": "preface-1ed.html#preface",
    "title": "First edition (2020)",
    "section": "1 Preface",
    "text": "1 Preface\nThis book covers different aspects of the use of the R language. Chapters 1 to 5 describe the R language itself. Later chapters describe extensions to the R language available through contributed packages, the grammar of data and the grammar of graphics. In this book, explanations are concise but contain pointers to additional sources of information, so as to encourage the development of a routine of independent exploration. This is not an arbitrary decision, this is the normal modus operandi of most of us who use R regularly for a variety of different problems. Some have called approaches like the one used here “learning the hard way,” but I would call it “learning to be independent.”\nI do not discuss statistics or data analysis methods in this book; I describe R as a language for data manipulation and display. The idea is for you to learn the R language in a way comparable to how children learn a language: they work out what the rules are, simply by listening to people speak and trying to utter what they want to tell their parents. Of course, small children receive some guidance, but they are not taught a prescriptive set of rules like when learning a second language at school. Instead of listening, you will read code, and instead of speaking, you will try to execute R code statements on a computer-i.e., you will try your hand at using R to tell a computer what you want it to compute. I do provide explanations and guidance, but the idea of this book is for you to use the numerous examples to find out by yourself the overall patterns and coding philosophy behind the R language. Instead of parents being the sound board for your first utterances in R, the computer will play this role. You will play by modifying the examples, see how the computer responds: does R understand you or not? Using a language actively is the most efficient way of learning it. By using it, I mean actually reading, writing, and running scripts or programs (copying and pasting, or typing ready-made examples from books or the internet, does not qualify as using a language).\nI have been using R since around 1998 or 1999, but I am still constantly learning new things about R itself and R packages. With time, it has replaced in my work as a researcher and teacher several other pieces of software: SPSS, Systat, Origin, MS-Excel, and it has become a central piece of the tool set I use for producing lecture slides, notes, books, and even web pages. This is to say that it is the most useful piece of software and programming language I have ever learned to use. Of course, in time it will be replaced by something better, but at the moment it is a key language to learn for anybody with a need to analyze and display data.\nWhat is a language? A language is a system of communication. R as a language allows us to communicate with other members of the R community, and with computers. As with all languages in active use, R evolves. New “words” and new “constructs” are incorporated into the language, and some earlier frequently used ones are relegated to the fringes of the corpus. I describe current usage and “modisms” of the R language in a way accessible to a readership unfamiliar with computer science but with some background in data analysis as used in biology, engineering, or the humanities.\nWhen teaching, I tend to lean toward challenging students, rather than telling an over-simplified story. There are two reasons for this. First, I prefer as a student, and I learn best myself, if the going is not too easy. Second, if I would hide the tricky bits of the R language, it would make the reader’s life much more difficult later on. You will not remember all the details; nobody could. However, you most likely will remember or develop a sense of when you need to be careful or should check the details. So, I will expose you not only to the usual cases, but also to several exceptions and counterintuitive features of the language, which I have highlighted with icons. Reading this book will be about exploring a new world; this book aims to be a travel guide, but neither a traveler’s account, nor a cookbook of R recipes.\nKeep in mind that it is impossible to remember everything about R! The R language, in a broad sense, is vast because its capabilities can be expanded with independently developed packages. Learning to use R consists of learning the basics plus developing the skill of finding your way in R and its documentation. In early 2020, the number of packages available in the Comprehensive R Archive Network (CRAN) broke the 15,000 barrier. CRAN is the most important, but not only, public repository for R packages. How good a command of the R language and packages a user needs depends on the type of activities to be carried out. This book attempts to train you in the use of the R language itself, and of popular R language extensions for data manipulation and graphical display. Given the availability of numerous books on statistical analysis with R, in the present book I will cover only the bare minimum of this subject. The same is true for package development in R. This book is somewhere in-between, aiming at teaching programming in the small: the use of R to automate the drudgery of data manipulation, including the different steps spanning from data input and exploration to the production of publication-quality illustrations.\nAs with all “rich” languages, there are many different ways of doing things in R. In almost all cases there is no one-size-fits-all solution to a problem. There is always a compromise involved, usually between time spent by the user and processing time required in the computer. Many of the packages that are most popular nowadays did not exist when I started using R, and many of these packages make new approaches available. One could write many different R books with a given aim using substantially different ways of achieving the same results. In this book, I limit myself to packages that are currently popular and/or that I consider elegantly designed. I have in particular tried to limit myself to packages with similar design philosophies, especially in relation to their interfaces. What is elegant design, and in particular what is a friendly user interface, depends strongly on each user’s preferences and previous experience. Consequently, the contents of the book are strongly biased by my own preferences. I have tried to write examples in ways that execute fast without compromising readability. I encourage readers to take this book as a starting point for exploring the very many packages, styles, and approaches which I have not described.\nI will appreciate suggestions for further examples, and notification of errors and unclear sections. Because the examples here have been collected from diverse sources over many years, not all sources are acknowledged. If you recognize any example as yours or someone else’s, please let me know so that I can add a proper acknowledgement. I warmly thank the students who have asked the questions and posed the problems that have helped me write this text and correct the mistakes and voids of previous versions. I have also received help on online forums and in person from numerous people, learned from archived e-mail list messages, blog posts, books, articles, tutorials, webinars, and by struggling to solve some new problems on my own. In many ways this text owes much more to people who are not authors than to myself. However, as I am the one who has written this version and decided what to include and exclude, as author, I take full responsibility for any errors and inaccuracies.\nWhy have I chosen the title “Learn R: As a Language”? This book is based on exploration and practice that aims at teaching to express various generic operations on data using the R language. It focuses on the language, rather than on specific types of data analysis, and exposes the reader to current usage and does not spare the quirks of the language. When we use our native language in everyday life, we do not think about grammar rules or sentence structure, except for the trickier or unfamiliar situations. My aim is for this book to help you grow to use R in this same way, to become fluent in R. The book is structured around the elements of languages with chapter titles that highlight the parallels between natural languages like English and the R language.\n\nI encourage you to approach R like a child approaches his or her mother tongue when first learning to speak: do not struggle, just play, and fool around with R! If the going gets difficult and frustrating, take a break! If you get a new insight, take a break to enjoy the victory!"
  },
  {
    "objectID": "contents-2ed.html",
    "href": "contents-2ed.html",
    "title": "Second edition (2024)",
    "section": "",
    "text": "The book cover"
  },
  {
    "objectID": "contents-2ed.html#book-citation",
    "href": "contents-2ed.html#book-citation",
    "title": "Second edition (2024)",
    "section": "Book citation",
    "text": "Book citation\nAphalo, Pedro J. (2024) Learn R: As a Language, 2 ed. Boca Raton: CRC/Taylor & Francis Ltd (The R Series), 466 pp. ISBN: 9781032516998. (466 pages, 191 color illustrations.)\n@Book{Aphalo2020,\n  author    = {Pedro J. Aphalo},\n  date      = {2024},\n  title     = {Learn R: As a Language},\n  edition   = {2},\n  isbn      = {9781032516998},\n  pagetotal = {466},\n  publisher = {CRC/Taylor & Francis Ltd},\n  series    = {The R Series},\n}"
  },
  {
    "objectID": "contents-2ed.html#preface",
    "href": "contents-2ed.html#preface",
    "title": "Second edition (2024)",
    "section": "Preface",
    "text": "Preface"
  },
  {
    "objectID": "contents-2ed.html#using-the-book-to-learn-r",
    "href": "contents-2ed.html#using-the-book-to-learn-r",
    "title": "Second edition (2024)",
    "section": "1. Using the Book to Learn R",
    "text": "1. Using the Book to Learn R\nIn this chapter, I describe how I imagine the book can be used most effectively to learn the R language. Learning R and remembering what one has previously learnt and forgotten makes it also necessary to use this book and other sources as references. Learning to use R effectively also involves learning how to search for information and how to ask questions from other users, for example through online forums. Thus, I also give advice on how to find answers to R-related questions and how to use the available documentation."
  },
  {
    "objectID": "contents-2ed.html#r-the-language-and-the-program",
    "href": "contents-2ed.html#r-the-language-and-the-program",
    "title": "Second edition (2024)",
    "section": "2. R: The language and the program",
    "text": "2. R: The language and the program\nI share some facts about the history and design of the R language so that you can gain a good vantage point from which to grasp the logic behind R’s features, making it easier to understand and remember them. You will learn the distinction between the R program itself and the front-end programs, like RStudio, frequently used together with R.\nYou will also learn how to interact with R when sitting at a computer. You will learn the difference between typing commands interactively and reading each partial result from R on the screen as you enter them, versus using R scripts containing multiple commands stored in a file to execute or run a “job” that saves results to another file for later inspection.\nI describe the steps taken in a typical scientific or technical study, including the data analysis workflow and the roles that R can play in it. I share my views on the advantages and disadvantages of textual command languages such as R compared to menu-driven user interfaces, frequently used in other statistics software. I discuss the role of textual languages and literate programming in the very important question of the reproducibility of data analyses and mention how I have used them while writing and typesetting this book."
  },
  {
    "objectID": "contents-2ed.html#base-r-words-and-sentences",
    "href": "contents-2ed.html#base-r-words-and-sentences",
    "title": "Second edition (2024)",
    "section": "3. Base R: “Words” and “Sentences”",
    "text": "3. Base R: “Words” and “Sentences”\nIn my experience, for those who are not familiar with computer programming languages, the best first step in learning the R language is to use it interactively by typing textual commands at the R console. This teaches not only the syntax and grammar rules, but also gives a glimpse at the advantages and flexibility of this approach to data analysis. In this chapter, I focus on the different simple values or items that can be stored and manipulated in R, as well as the role of computer program statements, the equivalent of “sentences” in natural languages.\nIn the first part of the chapter, you will use R to do everyday calculations that should be so easy and familiar that you will not need to think about the operations themselves. This easy start will give you a chance to focus on learning how to issue textual commands at the command prompt.\nLater in the chapter, you will gradually need to focus more on the R language and its grammar and less on how commands are entered. By the end of the chapter, you will be familiar with most of the kinds of simple “words” used in the R language and you will be able to read and write simple R statements.\nThroughout the chapter, I will occasionally show the equivalent of the R code in mathematical notation. If you are not familiar with the mathematical notation, you can safely ignore the mathematics, as long as you understand the diagrams and the R code."
  },
  {
    "objectID": "contents-2ed.html#base-r-collective-nouns",
    "href": "contents-2ed.html#base-r-collective-nouns",
    "title": "Second edition (2024)",
    "section": "4. Base R: “Collective Nouns”",
    "text": "4. Base R: “Collective Nouns”\nData set organisation and storage is one of the keys to efficient data analysis. How to keep together all the information that belongs together, say all measurements from an experiment and corresponding metadata such as treatments applied and/or dates. The title “collective nouns” is based on the idea that a data set is a collection of data objects.\nIn this chapter, you will familiarise with how data sets are usually managed in R. I use both abstract examples to emphasise the general properties of data sets and the R classes available for their storage and a few more specific examples to exemplify their use in a more concrete way. While in chapter 3 the focus was on atomic data types and objects, like vectors, useful for the storage of collections of values of a given type, like numbers, in the present chapter the focus is on the storage within a single object of heterogeneous data, such as a combination of factors, and character and numeric vectors. Broadly speaking, heterogeneous data containers.\nTo describe the structure of R objects I use diagrams similar to those in the previous chapter."
  },
  {
    "objectID": "contents-2ed.html#base-r-paragraphs-and-essays",
    "href": "contents-2ed.html#base-r-paragraphs-and-essays",
    "title": "Second edition (2024)",
    "section": "5. Base R: “Paragraphs” and “Essays”",
    "text": "5. Base R: “Paragraphs” and “Essays”\nFor those who have mainly used graphical user interfaces, understanding why and when scripts can help in communicating a certain data analysis protocol can be revelatory. As soon as a data analysis stops being trivial, describing the steps followed through a system of menus and dialogue boxes becomes extremely tedious. Moreover, graphical user interfaces tend to be difficult to extend or improve in a way that keeps step-by-step instructions valid across program versions and operating systems.\nMany times, exactly the same sequence of commands needs to be applied to different data sets, and scripts make both implementation and validation of such a requirement easy.\nIn this chapter, I will walk you through the use of R scripts, starting from an extremely simple script."
  },
  {
    "objectID": "contents-2ed.html#base-r-adding-new-words",
    "href": "contents-2ed.html#base-r-adding-new-words",
    "title": "Second edition (2024)",
    "section": "6. Base R: Adding New “Words”",
    "text": "6. Base R: Adding New “Words”\nIn earlier chapters we have only used base R features. In this chapter you will learn how to expand the range of features available. I start by discussing how to define and use new functions, operators, and classes. What are their semantics and how they contribute to conciseness and reliability of computer scripts and programs. Later I focus on using existing packages to share extensions to R and touch briefly on how they work. I do not consider the important, but more advanced question of packaging functions and classes into new R packages. Instead I discuss how packages are installed and used."
  },
  {
    "objectID": "contents-2ed.html#base-r-verbs-and-nouns-for-statistics",
    "href": "contents-2ed.html#base-r-verbs-and-nouns-for-statistics",
    "title": "Second edition (2024)",
    "section": "7. Base R: “Verbs” and “Nouns” for Statistics",
    "text": "7. Base R: “Verbs” and “Nouns” for Statistics\nThis chapter aims to give the reader an introduction to the approach used in base R for the computation of statistical summaries, the fitting of models to observations and tests of hypothesis. This chapter does not explain data analysis methods, statistical principles or experimental designs. There are many good books on the use of R for different kinds of statistical analyses (see further reading on page 241) but most of them tend to focus on specific statistical methods rather than on the commonalities among them. Although base R’s model fitting functions target specific statistical procedures, they use a common approach to model specification and for returning the computed estimates and test outcomes. This approach, also followed by many contributed extension packages, can be considered as part of the philosophy behind the R language. In this chapter, you will become familiar with the approaches used in R for calculating statistical summaries, generating (pseudo-)random numbers, sampling, fitting models, and carrying out tests of significance. We will use linear correlation, t-test, linear models, generalised linear models, non-linear models, and some simple multivariate methods as examples. The focus is on how to specify statistical models, contrasts and observations, how to access different components of the objects returned by the corresponding fit and summary functions, and how to use these extracted components in further computations or for customised printing and formatting."
  },
  {
    "objectID": "contents-2ed.html#r-extensions-data-wrangling",
    "href": "contents-2ed.html#r-extensions-data-wrangling",
    "title": "Second edition (2024)",
    "section": "8. R Extensions: Data Wrangling",
    "text": "8. R Extensions: Data Wrangling\nBase R and the recommended extension packages (installed by default) include many functions for manipulating data. The R distribution supplies a complete set of functions and operators that allow all the usual data manipulation operations. These functions have stable and well-described behaviour, so in my view, they should be preferred unless some of their limitations justify the use of alternatives defined in contributed packages. In the present chapter, I describe the new syntax introduced by the most popular contributed R extension packages aiming at changing (usually improving one aspect at the expense of another) in various ways how we can manipulate data in R. These independently developed packages extend the R language not only by adding new “words” to it but by supporting new ways of meaningfully connecting “words”—i.e., providing new “grammars” for data manipulation. While at the current stage of development of base R not breaking existing code has been the priority, several of the still “young” packages in the ‘tidyverse’ have prioritised experimentation with enhanced features over backwards compatibility. The development of ‘tidyverse’ packages seems to have initially emphasised users’ convenience more than encouraging safe/error-free user code. The design of package ‘data.table’ has prioritised performance at the expense of easy of use. I do not describe in depth these new approaches but instead only briefly compare them to base R highlighting the most important differences."
  },
  {
    "objectID": "contents-2ed.html#r-extensions-grammar-of-graphics",
    "href": "contents-2ed.html#r-extensions-grammar-of-graphics",
    "title": "Second edition (2024)",
    "section": "9. R Extensions: Grammar of Graphics",
    "text": "9. R Extensions: Grammar of Graphics\nThree main data plotting systems are available to R users: base R, package ‘lattice’ (Sarkar 2008), and package ‘ggplot2’ (Wickham and Sievert 2016); the last one being the most recent and currently most popular system available in R for plotting data. Even two different sets of graphics primitives (i.e., those used to produce the simplest graphical elements such as lines and symbols) are available in R, those in base R and a newer one in the ‘grid’ package (Murrell 2019).\nIn this chapter, you will learn the concepts of the layered grammar of graphics, on which package ‘ggplot2’ is based. You will also learn how to build several types of data plots with package ‘ggplot2’. As a consequence of the popularity and flexibility of ‘ggplot2’, many contributed packages extending its functionality have been developed and deposited in public repositories. However, I will focus mainly on package ‘ggplot2’ only briefly describing a few of these extensions."
  },
  {
    "objectID": "contents-2ed.html#base-r-and-extensions-data-sharing",
    "href": "contents-2ed.html#base-r-and-extensions-data-sharing",
    "title": "Second edition (2024)",
    "section": "10. Base R and Extensions: Data Sharing",
    "text": "10. Base R and Extensions: Data Sharing\nIn this chapter, you will learn how to exchange data between R and some other applications. Base R and the recommended packages (installed by default) include several functions for importing and exporting data. Contributed packages provide both replacements for some of these functions and support for several additional file formats. In the present chapter, I aim at describing both data input and output covering in detail only the most common “foreign” data formats (those not native to R). The function pairs save() and load(), and saveRDS() and readRDS(), which save and read data in R’s native formats, are described in chapter 4, sections 4.7.2 and 4.7.3 starting on page 118.\nData file formats that are foreign to R are not always well defined, making it necessary to reverse-engineer the algorithms needed to read them. These formats, even when clearly defined, may be updated by the developers of the foreign software that writes the files. Consequently, developing software to read and write files using foreign formats can easily result in long, messy, and ugly R scripts. We can also unwillingly write code that usually works but occasionally fails with specific files, or even worse, occasionally silently corrupts the imported data. The aim of this chapter is to provide guidance for finding functions for reading data encoded using foreign formats, covering both base R, including the ‘foreign’ package, and independently contributed packages. Such functions are well tested or validated and should be used whenever possible when importing data stored in foreign file formats."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Learn R: As a Language",
    "section": "",
    "text": "The book cover, 2 ed\n\n\nThis website supports the book Learn R: As a Language authored by Pedro J. Aphalo and published in The R Series by Chapman and Hall/CRC. The website was built and is maintained by the author of the book. The site is static and built using Quarto.\nBook citation:\n@Book{Aphalo2024,\n  author    = {Pedro J. Aphalo},\n  date      = {2024},\n  title     = {Learn R: As a Language},\n  edition   = 2,\n  isbn      = {9781032516998},\n  pagetotal = {466},\n  publisher = {Chapman \\& Hall/CRC/Taylor & Francis Ltd},\n  series    = {The R Series},\n}\n\n\n\nReuseCC BY-SA 4.0"
  },
  {
    "objectID": "contents-1ed.html",
    "href": "contents-1ed.html",
    "title": "First edition (2020)",
    "section": "",
    "text": "The book cover (1ed)"
  },
  {
    "objectID": "contents-1ed.html#book-citation",
    "href": "contents-1ed.html#book-citation",
    "title": "First edition (2020)",
    "section": "Book citation",
    "text": "Book citation\nAphalo, Pedro J. (2020) Learn R: As a Language, 1 ed. Boca Raton: CRC/Taylor & Francis Ltd (The R Series). ISBN: 9780367182533. (364 pages, 114 colour illustrations.)\n@Book{Aphalo2020,\n  author    = {Pedro J. Aphalo},\n  date      = {2020},\n  title     = {Learn R: As a Language},\n  edition   = {1},\n  isbn      = {9780367182533},\n  pagetotal = {364},\n  publisher = {CRC/Taylor & Francis Ltd},\n  series    = {The R Series},\n}"
  },
  {
    "objectID": "contents-1ed.html#preface",
    "href": "contents-1ed.html#preface",
    "title": "First edition (2020)",
    "section": "Preface",
    "text": "Preface"
  },
  {
    "objectID": "contents-1ed.html#r-the-language-and-the-program",
    "href": "contents-1ed.html#r-the-language-and-the-program",
    "title": "First edition (2020)",
    "section": "1. R: The language and the program",
    "text": "1. R: The language and the program\nIn this chapter you will learn some facts about the history and design aims behind the R language, its implementation in the R program, and how it is used in actual practice when sitting at a computer. You will learn the difference between typing commands interactively, reading each partial response from R on the screen as you type versus using R scripts to execute a “job” which saves results for later inspection by the user.\nI will describe the advantages and disadvantages of textual command languages such as R compared to menu-driven user interfaces as frequently used in other statistics software and occasionally also with R. I will discuss the role of textual languages in the very important question of reproducibility of data analyses.\nFinally you will learn about the different types and sources of help available to R users, and how to best make use of them."
  },
  {
    "objectID": "contents-1ed.html#the-r-language-words-and-sentences",
    "href": "contents-1ed.html#the-r-language-words-and-sentences",
    "title": "First edition (2020)",
    "section": "2. The R language: “Words” and “sentences”",
    "text": "2. The R language: “Words” and “sentences”\nIn my experience, for those not familiar with computer programming languages, the best first step in learning the R language is to use it interactively by typing tex- tual commands at the console or command line. This will teach not only the syntax and grammar rules, but also give you a glimpse at the advantages and flexibility of this approach to data analysis.\nIn the first part of the chapter we will use R to do everyday calculations that should be so easy and familiar that you will not need to think about the operations themselves. This easy start will give you a chance to focus on learning how to issue textual commands at the command prompt.\nLater in the chapter, you will gradually need to focus more on the R language and its grammar and less on how commands are entered. By the end of the chapter you will be familiar with most of the kinds of “words” used in the R language and you will be able to write simple “sentences” in R.\nAlong the chapter, I will occasionally show the equivalent of the R code in math- ematical notation. If you are not familiar with the mathematical notation, you can safely ignore it, as long as you understand the R code."
  },
  {
    "objectID": "contents-1ed.html#the-r-language-paragraphs-and-essays",
    "href": "contents-1ed.html#the-r-language-paragraphs-and-essays",
    "title": "First edition (2020)",
    "section": "3. The R language: “Paragraphs” and “essays”",
    "text": "3. The R language: “Paragraphs” and “essays”\nFor those who have mainly used graphical user interfaces, understanding why and when scripts can help in communicating a certain data analysis protocol can be revelatory. As soon as a data analysis stops being trivial, describing the steps fol- lowed through a system of menus and dialogue boxes becomes extremely tedious. Moreover, graphical user interfaces tend to be difficult to extend or improve in a way that keeps step-by-step instructions valid across program versions and operating systems.\nMany times, exactly the same sequence of commands needs to be applied to different data sets, and scripts make both implementation and validation of such a requirement easy.\nIn this chapter, I will walk you through the use of R scripts, starting from an extremely simple script."
  },
  {
    "objectID": "contents-1ed.html#the-r-language-statistics",
    "href": "contents-1ed.html#the-r-language-statistics",
    "title": "First edition (2020)",
    "section": "4. The R language: Statistics",
    "text": "4. The R language: Statistics\nThis chapter aims to give the reader only a quick introduction to statistics in base R, as there are many good texts on the use of R for different kinds of statistical analyses (see further reading on page 161). Although many of base R’s functions are specific to given statistical procedures, they use a particular approach to model specification and for returning the computed values that can be considered a part of the R language. Here you will learn the approaches used in R for calculating sta- tistical summaries, generating (pseudo-)random numbers, sampling, fitting models and carrying out tests of significance. We will use linear correlation, t-test, linear models, generalized linear models, non-linear models and some simple multivari- ate methods as examples. My aim is teaching how to specify models, contrasts and data used, and how to access different components of the objects returned by the corresponding fit and summary functions."
  },
  {
    "objectID": "contents-1ed.html#the-r-language-adding-new-words",
    "href": "contents-1ed.html#the-r-language-adding-new-words",
    "title": "First edition (2020)",
    "section": "5. The R language: Adding new “words”",
    "text": "5. The R language: Adding new “words”\nIn earlier chapters we have only used base R features. In this chapter you will learn how to expand the range of features available. In the first part of the chapter we will focus on using existing packages and how they expand the functionality of R. In the second part you will learn how to define new functions, operators and classes. We will not consider the important, but more advanced question of packaging functions and classes into new R packages."
  },
  {
    "objectID": "contents-1ed.html#new-grammars-of-data",
    "href": "contents-1ed.html#new-grammars-of-data",
    "title": "First edition (2020)",
    "section": "6. New grammars of data",
    "text": "6. New grammars of data\nBase R and the recommended extension packages (installed by default) include many functions for manipulating data. The R distribution supplies a complete set of functions and operators that allow all the usual data manipulation operations. These functions have stable and well-described behavior, so they should be pre- ferred unless some of their limitations justify the use of alternatives defined in contributed packages. In the present chapter we aim at describing the new syn- taxes introduced by the most popular of these contributed R extension packages aiming at changing (usually improving one aspect at the expense of another) in var- ious ways how we can manipulate data in R. These independently developed pack- ages extend the R language not only by adding new “words” to it but by supporting new ways of meaningfully connecting “words”—i.e., providing new “grammars” for data manipulation."
  },
  {
    "objectID": "contents-1ed.html#grammar-of-graphics",
    "href": "contents-1ed.html#grammar-of-graphics",
    "title": "First edition (2020)",
    "section": "7. Grammar of graphics",
    "text": "7. Grammar of graphics\nThree main data plotting systems are available to R users: base R, package ‘lattice’ (Sarkar 2008) and package ‘ggplot2’ (Wickham and Sievert 2016), the last one be- ing the most recent and currently most popular system available in R for plotting data. Even two different sets of graphics primitives (i.e., those used to produce the simplest graphical elements such as lines and symbols) are available in R, those in base R and a newer one in the ‘grid’ package (Murrell 2011).\nIn this chapter you will learn the concepts of the grammar of graphics, on which package ‘ggplot2’ is based. You will also learn how to build several types of data plots with package ‘ggplot2’. As a consequence of the popularity and flexibility of ‘ggplot2’, many contributed packages extending its functionality have been devel- oped and deposited in public repositories. However, I will focus mainly on package ‘ggplot2’ only briefly describing a few of these extensions."
  },
  {
    "objectID": "contents-1ed.html#data-import-and-export",
    "href": "contents-1ed.html#data-import-and-export",
    "title": "First edition (2020)",
    "section": "8. Data import and export",
    "text": "8. Data import and export\nBase R and the recommended packages (installed by default) include several func- tions for importing and exporting data. Contributed packages provide both re- placements for some of these functions and support for several additional file formats. In the present chapter, I aim at describing both data input and output covering in detail only the most common “foreign” data formats (those not native to R).\nData file formats that are foreign to R are not always well defined, making it necessary to reverse-engineer the algorithms needed to read them. These formats, even when clearly defined, may be updated by the developers of the foreign soft- ware that writes the files. Consequently, developing software to read and write files using foreign formats can easily result in long, messy, and ugly R scripts. We can also unwillingly write code that usually works but occasionally fails with specific files, or even worse, occasionally silently corrupts the imported data. The aim of this chapter is to provide guidance for finding functions for reading data encoded using foreign formats, covering both base R, including the ‘foreign’ package, and independently contributed packages. Such functions are well tested or validated.\nIn this chapter you will familiarize yourself with how to exchange data between R and other applications. The functions save() and load(), and saveRDS() and readRDS(), all of which save and read data in R’s native formats, are described in sections 2.16.2 and 2.16.3 starting on page 79."
  },
  {
    "objectID": "contents-1ed.html#grammar-of-graphics-fonts",
    "href": "contents-1ed.html#grammar-of-graphics-fonts",
    "title": "First edition (2020)",
    "section": "9. Grammar of Graphics: Fonts",
    "text": "9. Grammar of Graphics: Fonts"
  },
  {
    "objectID": "contents-1ed.html#grammar-of-graphics-color-palettes",
    "href": "contents-1ed.html#grammar-of-graphics-color-palettes",
    "title": "First edition (2020)",
    "section": "10. Grammar of Graphics: Color palettes",
    "text": "10. Grammar of Graphics: Color palettes"
  },
  {
    "objectID": "contents-1ed.html#a.-case-timeline-plots",
    "href": "contents-1ed.html#a.-case-timeline-plots",
    "title": "First edition (2020)",
    "section": "A. Case: Timeline plots",
    "text": "A. Case: Timeline plots"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learn R: As a Language",
    "section": "",
    "text": "1 The book in a nutshell\nThe second edition (yellow-red wordcloud cover) of my book Learn R: As a Language has publication date 26 April 2024. The R package ’learnrbook’ available through CRAN contains data and the R code from scripts and chunks in the book. Package ‘learnrboo’ versions &gt;= 2.0.0 support both book editions of the book. I typeset the book using \\(\\LaTeX\\) and R package ‘knitr’. The 2nd edition includes many new diagrams and flowcharts that help explain the structure of R code, the structure of R objects, and the control of execution constructs.\n\n\n\nStructure of a vector\n\n\n\n\n\nif code construct\n\n\nThe book is published as paperback and hardback printed books and as an eBook. The page count has increased from 364 to 466, and the number of colour illustrations from 114 to 191. The price increase of the paperback is minimal, from 58.99 to 59.99 pounds. The hardback of the 2nd edition at 150 pounds is 5 pounds cheaper than the first edition. The 2nd edition of the book is available from the publisher through the book’s web page at a 20% discount until 31 July 2024 when using the discount code below.\n\n\n\n\n\n\n\nDiscount code: SMA22\n\n\nThe book is also available at brick and mortar booksellers and through web stores, at prices that may differ from the publisher’s prices.\n\n\n2 News\n[April 2024] Second edition published. The price of the eBook is the same as for the paperback. Until 31 July there is a 20% discount available to all at the the publisher through the book’s web page. Supplementary material is now available as web pages at the my website with some of the most relevant pages highlighted at the R index page of the site.\n[September 2021] I have made available through this website supplementary chapters for the book (over 100 pages). These are typeset using the same design as the book itself and numbering of chapters and pages continues from where they end in the book. These chapters are still work in progress. After further revision I intend to add the code they contain also to package ‘learnrbook’. They are released under a CC-BY-SA 4.0 licence.\n[July 2021] Only two small changes to the code chunks are needed to avoid deprecation messages from ‘tidyverse’ packages. The ‘learnrbook’ package (1.0.2) adds the R code for all code chunks in the book as executable and editable .R files. Additional material related to my ‘ggplot2’ extensions is available in the vignettes of my packages ‘gginnards’, ‘ggpp’ and ‘ggpmisc’, all available through CRAN.\n\n\n3 Issues\nReports of errors and suggestions for enhancements are welcome, preferably as Issues raised at https://github.com/aphalo/learnr-book-crc/issues; the source of the book is at https://github.com/aphalo/learnr-book-crc.\n\n\n\n\nThe book cover\n\n\n\n\n\n\n\nReuseCC BY-SA 4.0"
  },
  {
    "objectID": "preface-2ed.html",
    "href": "preface-2ed.html",
    "title": "Second edition (2024)",
    "section": "",
    "text": "The book cover"
  },
  {
    "objectID": "preface-2ed.html#preface",
    "href": "preface-2ed.html#preface",
    "title": "Second edition (2024)",
    "section": "1 Preface",
    "text": "1 Preface\n\n\n\n\n\n\n–\n\n\n\nSuppose that you want to teach the ‘cat’ concept to a very young child. Do you explain that a cat is a relatively small, primarily carnivorous mammal with retractible claws, a distinctive sonic output, etc.? I’ll bet not. You probably show the kid a lot of different cats, saying `kitty’ each time, until it gets the idea. To put it more generally, generalisations are best made by abstraction from experience.\nR. P. Boas Can we make mathematics intelligible?, 1981.\n\n\nWhy did I choose ``Learn R: As a Language’’ as the title? This book is based on exploration and practice that aims at teaching how to express various operations on data using the R language. It focuses on the language, rather than on specific types of data analysis, exposes the reader to current usage, and does not spare the quirks of the language. When we use our native language in everyday life, we do not think about grammar rules or sentence structure, except for the trickier or unfamiliar situations. My aim is for this book to help readers learn to use R in this same way, i.e., to become fluent in R. The book is structured around the elements of natural languages like English with chapter titles that highlight the parallels between them and the R language.\nLearn R: As a Language is different from other books about R in that it emphasises the learning of the language itself, rather than how to use it to address specific data analysis tasks. My aim has been to enable readers to use R to implement original solutions to the data analysis and data visualisation tasks they encounter. The use of quantitative methods and data analysis has become more frequent in fields with limited long-term tradition in their use, like humanities, or, the complexity of the methods used has dramatically increased, like in Biology. Such trends can be expected to continue in the future.\nCurrently, many students of biological and environmental sciences learn to use R in courses about statistics or data analysis. However, this is frequently not in enough depth to effectively use R in scripts for automating data analyses or to ensure their reproducibility. There are also many researchers in various fields who are already familiar with statistical principles and willing to switch from other software to R. Learn R: As a Language is written with these readers in mind to serve both as a textbook and as a reference.\nA language is a system of communication. Basic concepts and operations are based on abstractions that are shared across programming languages and relevant to programs of all sizes and complexities; these abstractions are explained in the book together with their implementation in the R language. Other abstractions and programming concepts, outside the scope of this book, are relevant to large and complex pieces of software meant to be widely distributed. In other words, Learn R: As a Language aims at teaching and supporting programming in the small: the use of R to automate the drudgery of data manipulation, including the different steps spanning from data input and exploration to the production of publication-ready illustrations and reproducible data-based reports.\nUsing a language actively is the most efficient way of learning it. By using it, I mean actually reading, writing, and running scripts or programs. Learn R: As a Language supports learning the R language in a way comparable to how children learn to speak: they work out what the rules are, simply by listening to people speak and trying to utter what they want to tell their parents. Of course, small children also receive guidance through feedback, but they are not taught a prescriptive set of rules like when learning a second language at school. Instead of listening, readers will read and run code, and instead of speaking, readers will write and try to run R-language code on a computer. I do provide explanations and guidance, as understanding how R works greatly helps with its use. However, the approach I encourage in this book is for readers to play with the numerous examples and to create variations upon them, to find out by themselves the patterns behind the R language. Instead of parents being the sounding board for the first utterances of readers new to R, the computer will play this role. Although working through the examples in Learn R: As a Language in a group of peers or in class is beneficial, the book is designed to be useful also in the absence of such support.\nChanges in the second edition: I edited the text from the first edition to correct all errors and outdated examples or explanations known to me. This revised second edition reflects changes in R and the contributed packages used in the book. Very little of the code from the first edition had stopped working but deprecations meant that a few examples triggered messages or warnings, and will eventually fail. Recent (\\(&gt;\\),4.0.0) versions of R have significant enhancements, including the new pipe operator described and used in this second edition. Packages have also evolved, acquiring new features like a new approach to flipping plots in ‘ggplot2’.\nI have aimed at making the book more accessible to readers with no previous experience in computer programming. Feedback from readers and reviewers highlighted a few gaps in the content and some difficult-to-follow explanations. I revised the text, in some cases changing the sequence of presentation. I added diagrams to illustrate the structure of different types of objects and flowcharts to describe how program constructs work. I added tables listing groups of related functions. New sections cover character string operations, and details of data wrangling in R. Some of the most frequently asked questions about R are answered in the text and separately indexed. All exercises or ``playgrounds’’ are numbered to facilitate their use as class work and the sharing of model answers. As the first edition has been frequently found useful as a reference, I expanded the already thorough indexing and added more cross-references connecting related sections across the whole book.\nAn additional change is in my view about packages ‘dplyr’ and ‘tidyr’, part of the ‘tidyverse’. I have come to think that the rate of development of these two packages can make them difficult for users for whom data analysis is just one aspect of their occupation. As these packages are widely used, I emphasise more than in the first edition the differences between functions and classes from packages ‘dplyr’ and ‘tidyr’ and equivalent ones from base R. I added a section on working with dates and times using the ‘lubridate’ package. I updated and reorganised the chapter describing package ‘ggplot2’ and some of its extensions.\nIn numbers, the page count has increased by 27%, the number of figures from eight to twenty-six plus nine in-text diagrams, and tables from none to seven. As for the design, text boxes have been replaced by call-outs marked with marginal bars. In addition, starting from version 2.0.0, the ‘learnrbook’ package supports the first and second editions of the book. It contains data, scripts, and all the code examples from both editions. It also helps with the installation of all the packages used in the book. The website at https://www.learnr-book.info/ provides updated open-access content."
  },
  {
    "objectID": "preface-2ed.html#acknowledgements",
    "href": "preface-2ed.html#acknowledgements",
    "title": "Second edition (2024)",
    "section": "2 Acknowledgements",
    "text": "2 Acknowledgements\nI thank Jaakko Heinonen for introducing me in the late 1990s to the then new R. Along the way many experts have answered my questions in usenet and more recently in stackoverflow. I wish to warmly thank members of my research group, students, collaborators, authors of books, and people I have met online or at conferences. They have made it possible for me to write this book. I am specially indebted to Dan Yavorsky, Tarja Lehto, Titta Kotilainen, Tautvydas Zalnierius, Fang Wang, Yan Yan, Neha Rai, Markus Laurel, Brett Cooper, Viivi Lindholm, Matj Rzehulka, Zuzana Svarna, colleagues, students, and anonymous reviewers for many very helpful comments on the draft manuscript and/or the first edition. Rob Calver, editor of both editions, provided advice and encouragement with great patience. Paul Boyd, Shashi Kumar, Ashraf Reza, Vaishali Singh, Lara Spieker, and Sherry Thomas efficiently helped with different aspects of this project.\nThe writing of this second edition was helped by a six-month sabbatical granted by the Faculty of Biological and Environmental Sciences of the University of Helsinki, Finland. I thank Prof. Kurt Fagerstedt for his support.\nIn many ways this text owes more to people who are not authors than to myself. However, as I am the one who has written Learn R: As a Language and decided what to include and exclude, I take full responsibility for any errors and inaccuracies.\nPedro J. Aphalo\nHelsinki, March 2024"
  }
]